# hopenet_mxJiang

This project aims to identify one's gazing directions in a video, by converting Deep-Head-Pose Hopenet in Pytorch to MXNet Gluon. 

The accuracy of this gluon version is close to the original Pytorch version. 

The pre-trained parameters and architectures can be found in the directory model. They can be used to test on videos.

The original Pytorch algorithm can be found here: https://github.com/natanielruiz/deep-head-pose.
